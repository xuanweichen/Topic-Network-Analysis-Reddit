{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practise - Topic Network Analysis in Online Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise variables\n",
    "num_of_chats = 8\n",
    "delta = np.timedelta64(1,'D')\n",
    "\n",
    "post_paths = [None] * num_of_chats\n",
    "comment_paths = [None] * num_of_chats\n",
    "df_posts = [None] * num_of_chats\n",
    "df_comments = [None] * num_of_chats\n",
    "df_preprocessed_list = [None] * num_of_chats\n",
    "timespan_list = [None] * num_of_chats\n",
    "chat_doc_list = [None] * num_of_chats\n",
    "chat_doc_list_ready = [None] * num_of_chats\n",
    "chat_numOfSamples_list = [None] * num_of_chats\n",
    "chat_id2word = [None] * num_of_chats\n",
    "chat_corpus = [None] * num_of_chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "\n",
    "'''Ethereum'''\n",
    "post_paths[0] = '../data/ethereum_posts_reddit.csv'\n",
    "comment_paths[0] = '../data/ethereum_comments_reddit.csv'\n",
    "\n",
    "'''Litecoin'''\n",
    "post_paths[1] = '../data/litecoin_posts_reddit.csv'\n",
    "comment_paths[1] = '../data/litecoin_comments_reddit.csv'\n",
    "\n",
    "'''Dogecoin'''\n",
    "post_paths[2] = '../data/dogecoin_posts_reddit.csv'\n",
    "comment_paths[2] = '../data/dogecoin_comments_reddit.csv'\n",
    "\n",
    "'''NEM'''\n",
    "post_paths[3] = '../data/nem_posts_reddit.csv'\n",
    "comment_paths[3] = '../data/nem_comments_reddit.csv'\n",
    "\n",
    "'''Ripple'''\n",
    "post_paths[4] = '../data/ripple_posts_reddit.csv'\n",
    "comment_paths[4] = '../data/ripple_comments_reddit.csv'\n",
    "\n",
    "'''Binance'''\n",
    "post_paths[5] = '../data/binance_posts_reddit.csv'\n",
    "comment_paths[5] = '../data/binance_comments_reddit.csv'\n",
    "\n",
    "'''Iota'''\n",
    "post_paths[6] = '../data/iota_posts_reddit.csv'\n",
    "comment_paths[6] = '../data/iota_comments_reddit.csv'\n",
    "\n",
    "'''Cardano'''\n",
    "post_paths[7] = '../data/cardano_posts_reddit.csv'\n",
    "comment_paths[7] = '../data/cardano_comments_reddit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv files\n",
    "for i in range(num_of_chats):\n",
    "    df_posts[i] = pd.read_csv(post_paths[i])\n",
    "    df_comments[i] = pd.read_csv(comment_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_chats):\n",
    "    df_preprocessed_list[i] = preprocess_data(df_posts[i], df_comments[i])\n",
    "    timespan_list[i] = get_timespan(df_preprocessed_list[i])\n",
    "    \n",
    "if all(timespan == timespan_list[0] for timespan in timespan_list):\n",
    "    timespan = timespan_list[0]\n",
    "else:\n",
    "    raise Exception(\"ERROR: Please make sure that all datasets have the same time span!\")\n",
    "    \n",
    "num_of_timeframes, timeframe_list = get_timeframes(timespan, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_timeframes_str = get_formatted_timeframes_str(timeframe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_chats):\n",
    "    # Split document based on time frame\n",
    "    chat_doc_list[i] = split_doc_by_timeframe(timeframe_list, df_preprocessed_list[i])\n",
    "    # Process data (tokenisation, building N-grams and lemmatisation)\n",
    "    chat_doc_list_ready[i] = [process_words(doc) for doc in chat_doc_list[i]]\n",
    "    # Calculatet the number of samples per timeframe for each chat\n",
    "    chat_numOfSamples_list[i] = [len(doc) for doc in chat_doc_list[i]]\n",
    "    # Create the Dictionary and Corpus for Topic Modeling\n",
    "    chat_id2word[i], chat_corpus[i] = convert_to_bagOfWords(chat_doc_list_ready[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat_processed = get_df_processed(formatted_timeframes_str, chat_numOfSamples_list[0], chat_doc_list_ready[0])\n",
    "df_chat_processed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise variables\n",
    "num_of_topics = 10\n",
    "num_topics_list = [num_of_topics] * num_of_timeframes\n",
    "chat_lda_model_list = [None] * num_of_chats\n",
    "chats_topics_list = [None] * num_of_chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_chats):\n",
    "    chat_lda_model_list[i] = get_lda_models(chat_corpus[i], chat_id2word[i], num_topics_list)\n",
    "    chats_topics_list[i] = get_topics(chat_lda_model_list[i], num_topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat_topics = get_df_topics(chats_topics_list[0])\n",
    "df_chat_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise variables\n",
    "G_list = [None] * num_of_timeframes\n",
    "node_pair_list = [None] * num_of_timeframes\n",
    "dates = np.arange('2021-01-01', '2021-02-28', dtype='datetime64[D]')\n",
    "\n",
    "# Re-scaled lower bound & upper bound\n",
    "new_min = 0.8\n",
    "new_max = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_timeframes):\n",
    "    topics_list = [None] * num_of_chats\n",
    "    for j in range(num_of_chats):\n",
    "        topics_list[j] = chats_topics_list[j][i]\n",
    "    G_list[i], node_pair_list[i] = get_network_graph(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fig = plt.figure(i, figsize=(24, 12))\n",
    "    plt.axis('off')\n",
    "    plt.title(dates[i], fontsize = 18)\n",
    "    pos = nx.spring_layout(G_list[i], k=0.3)\n",
    "    d = dict(G_list[i].degree)\n",
    "\n",
    "    widths = nx.get_edge_attributes(G_list[i], 'betweenness')\n",
    "    \n",
    "    values = widths.values()\n",
    "    w_min = min(values)\n",
    "    w_max = max(values)\n",
    "    \n",
    "    if w_min != w_max:\n",
    "        widths = {key: ((v - w_min) / (w_max - w_min)) * (new_max - new_min) + new_min  for (key, v) in widths.items()}\n",
    "\n",
    "    nx.draw_networkx_nodes(G_list[i], pos = pos, node_size =[v * 100 for v in d.values()], with_labels=True, node_color = 'skyblue', alpha = 0.9)\n",
    "    nx.draw_networkx_edges(G_list[i], pos = pos, width = list(widths.values()), edge_color = 'grey', alpha = 0.8)\n",
    "    nx.draw_networkx_labels(G_list[i], pos = pos,font_size = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â€¢ Centrality measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### < Degree centrality >\n",
    "The degree of a node is the number of other nodes to which it is connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = []\n",
    "for i in range(num_of_timeframes):\n",
    "    degree_centrality = nx.degree_centrality(G_list[i])\n",
    "    dc = dc + sorted(degree_centrality.items(), key=lambda x:x[1], reverse=True)[:3]\n",
    "    \n",
    "dc = np.reshape(dc, (58, 6))\n",
    "df_dc = pd.DataFrame(dc)\n",
    "df_dc.index = dates\n",
    "for i in range(1, 6, 2):\n",
    "    df_dc[i] = df_dc[i].astype(float).round(2)\n",
    "\n",
    "df_dc.rename(columns={0: 'Top 1', 1: 'Degree centrality 1',\n",
    "                      2: 'Top 2', 3: 'Degree centrality 2',\n",
    "                      4: 'Top 3', 5: 'Degree centrality 3',}, inplace=True)\n",
    "df_dc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfi.export(df_dc.head(), '../image/degree_centrality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_top3_centralities = list(df_dc['Top 1']) + list(df_dc['Top 2']) + list(df_dc['Top 3'])\n",
    "df_dc_top3_centralities = pd.DataFrame(dc_top3_centralities)\n",
    "df_dc_value_counts = df_dc_top3_centralities[0].value_counts().rename_axis('Topics').reset_index(name='Counts')\n",
    "df_dc_value_counts['Percentage'] = df_dc_value_counts['Counts'].div(len(dc_top3_centralities)).apply(lambda x: format(x, '.1%'))\n",
    "df_dc_value_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfi.export(df_dc_value_counts.head(), '../image/value_count_degree_centrality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dc['Time interval'][(df_dc['Top 1'] == 'buy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### < Betweenness centrality >\n",
    "Betweenness centrality quantifies the number of times a node acts as a bridge(or \"broker\") along the shortest path between two other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = []\n",
    "for i in range(num_of_timeframes):\n",
    "    betweenness_centrality = nx.betweenness_centrality(G_list[i])\n",
    "    bc = bc + sorted(betweenness_centrality.items(), key=lambda x:x[1], reverse=True)[:3]\n",
    "    \n",
    "bc = np.reshape(bc, (58, 6))\n",
    "df_bc = pd.DataFrame(bc)\n",
    "df_bc.index = dates\n",
    "for i in range(1, 6, 2):\n",
    "    df_bc[i] = df_bc[i].astype(float).round(2)\n",
    "\n",
    "df_bc.rename(columns={0: 'Top 1', 1: 'Betweenness centrality 1',\n",
    "                      2: 'Top 2', 3: 'Betweenness centrality 2',\n",
    "                      4: 'Top 3', 5: 'Betweenness centrality 3',}, inplace=True)\n",
    "df_bc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfi.export(df_bc.head(), '../image/betweenness_centrality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_top3_centralities = list(df_bc['Top 1']) + list(df_bc['Top 2']) + list(df_bc['Top 3'])\n",
    "df_bc_top3_centralities = pd.DataFrame(bc_top3_centralities)\n",
    "df_bc_value_counts = df_bc_top3_centralities[0].value_counts().rename_axis('Topics').reset_index(name='Counts')\n",
    "df_bc_value_counts['Percentage'] = df_bc_value_counts['Counts'].div(len(bc_top3_centralities)).apply(lambda x: format(x, '.1%'))\n",
    "df_bc_value_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfi.export(df_bc_value_counts.head(), '../image/value_count_betweenness_centrality.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_topics_list[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â€¢ Changes in topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_topics_list = [None] * num_of_timeframes\n",
    "for i in range(num_of_timeframes):\n",
    "    tf_chat_topics_list = []\n",
    "    for chat_topics_list in chats_topics_list:\n",
    "        tf_chat_topics_list.append(chat_topics_list[i])\n",
    "    union_topics_list[i] = list(set().union(*tf_chat_topics_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [len(topics) for topics in union_topics_list]\n",
    "num_new_topics = [None] * num_of_timeframes\n",
    "num_preexisting_topics = [None] * num_of_timeframes\n",
    "num_disappearing_topics = [None] * num_of_timeframes\n",
    "perc_new_topics = [None] * num_of_timeframes\n",
    "perc_preexisting_topics = [None] * num_of_timeframes\n",
    "\n",
    "\n",
    "for i in range(num_of_timeframes-1):\n",
    "    num_new_topics[i+1] = len(list(set(union_topics_list[i+1]) - set(union_topics_list[i])))\n",
    "    num_preexisting_topics[i+1] = len(list(set(union_topics_list[i+1]) & set(union_topics_list[i])))\n",
    "    num_disappearing_topics[i+1] = len(list(set(union_topics_list[i]) - set(union_topics_list[i+1])))\n",
    "    perc_new_topics[i+1] = num_new_topics[i+1] / num_topics[i-1]\n",
    "    perc_preexisting_topics[i+1] = num_preexisting_topics[i+1] / num_topics[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'No. of topics': num_topics,\n",
    "        'No. of new topics': num_new_topics,\n",
    "        '% new topics': perc_new_topics,\n",
    "        'No. of pre-existing topics': num_preexisting_topics,\n",
    "        '% pre-existing topics': perc_preexisting_topics,\n",
    "        'No. of disappearing topics': num_disappearing_topics}\n",
    "\n",
    "\n",
    "df_topology = pd.DataFrame(data)\n",
    "df_topology.index = dates #['TF ' + str(i+1) for i in range(n)]\n",
    "df_topology = df_topology.fillna(0)\n",
    "\n",
    "df_topology['No. of new topics']= df_topology['No. of new topics'].astype(int)\n",
    "df_topology['No. of pre-existing topics']= df_topology['No. of pre-existing topics'].astype(int)\n",
    "df_topology['No. of disappearing topics']= df_topology['No. of disappearing topics'].astype(int)\n",
    "\n",
    "df_topology['% new topics']= df_topology['% new topics'].apply(lambda x: float(format(x*100, '.1f')))\n",
    "df_topology['% pre-existing topics']= df_topology['% pre-existing topics'].apply(lambda x: float(format(x*100, '.1f')))\n",
    "\n",
    "df_topology.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18, 9)})\n",
    "num_plot = ['No. of topics', 'No. of new topics','No. of pre-existing topics', 'No. of disappearing topics']\n",
    "ax = df_topology[num_plot].plot(marker='o')\n",
    "ax.set_title('Time series: Change of number of topics', fontsize=20)\n",
    "ax.set_ylabel('Number', fontsize=15)\n",
    "ax.set_xlim('2020-12-31', '2021-02-28')\n",
    "plt.savefig('../image/Time series 1.png', dpi = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18, 6)})\n",
    "perc_plot = ['% new topics', '% pre-existing topics']\n",
    "ax = df_topology[perc_plot].plot(marker='o')\n",
    "ax.set_title('Time series for percentage change of number of topics', fontsize=20)\n",
    "ax.set_ylabel('% Percentage', fontsize=15)\n",
    "ax.set_xlim('2020-12-31', '2021-02-28')\n",
    "plt.savefig('../image/Time series 2.png', dpi = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
